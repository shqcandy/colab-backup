{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMg1VrM6Yfs+Dt2MTBOjuCR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shqcandy/colab-backup/blob/master/dl-imooc-259/chapter1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9H5VCv3btEF",
        "colab_type": "code",
        "outputId": "98cd4491-61f5-46bc-cab2-09d67e2c7218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test)\n",
        "\n",
        "model.metrics_names\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport tensorflow as tf\\nprint(tf.__version__)\\n\\nmnist = tf.keras.datasets.mnist\\n\\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n\\nmodel = tf.keras.models.Sequential([\\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\\n  tf.keras.layers.Dense(128, activation='relu'),\\n  tf.keras.layers.Dropout(0.2),\\n  tf.keras.layers.Dense(10, activation='softmax')\\n])\\n\\nmodel.compile(optimizer='adam',\\n              loss='sparse_categorical_crossentropy',\\n              metrics=['accuracy'])\\n\\nmodel.fit(x_train, y_train, epochs=5)\\nmodel.evaluate(x_test, y_test)\\n\\nmodel.metrics_names\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugP_a_rHx7cx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(x_img_train, y_label_train),(x_img_test, y_label_test) = cifar10.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvHbx55wo_2M",
        "colab_type": "code",
        "outputId": "c8aa8306-c4f2-46d9-8852-f3621ae1d63c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "def get_mul(*nums):\n",
        "    ret = 1\n",
        "    for num in nums:\n",
        "        ret *= num\n",
        "    return ret\n",
        "\n",
        "class CifarData:\n",
        "    def __init__(self, data, label, need_shuffle):\n",
        "        #index = [True if item[0] in [0, 1] else False for item in label]\n",
        "        # print(set(index))\n",
        "        index = [True for item in label]\n",
        "        self._data = data[index]\n",
        "        self._data = np.reshape(self._data, [self._data.shape[0], get_mul(*list(self._data.shape)[1:])])\n",
        "        self._data = self._data / 127.5 - 1\n",
        "        # self._labels = label[index]\n",
        "        # self._labels = np.reshape(np.eye(10)[label[index]], (-1, 10))\n",
        "        self._labels = np.reshape(label, (-1,))\n",
        "        print(self._data.shape)\n",
        "        print(self._labels.shape)\n",
        "        # print(self._labels)\n",
        "        \n",
        "        self._num_examples = self._data.shape[0]\n",
        "        self._need_shuffle = need_shuffle\n",
        "        self._indicator = 0\n",
        "        if self._need_shuffle:\n",
        "            self._shuffle_data()\n",
        "            \n",
        "    def _shuffle_data(self):\n",
        "        # [0,1,2,3,4,5] -> [5,3,2,4,0,1]\n",
        "        p = np.random.permutation(self._num_examples)\n",
        "        self._data = self._data[p]\n",
        "        self._labels = self._labels[p]\n",
        "    \n",
        "    def next_batch(self, batch_size):\n",
        "        \"\"\"return batch_size examples as a batch.\"\"\"\n",
        "        end_indicator = self._indicator + batch_size\n",
        "        if end_indicator > self._num_examples:\n",
        "            if self._need_shuffle:\n",
        "                self._shuffle_data()\n",
        "                self._indicator = 0\n",
        "                end_indicator = batch_size\n",
        "            else:\n",
        "                raise Exception(\"have no more examples\")\n",
        "        if end_indicator > self._num_examples:\n",
        "            raise Exception(\"batch size is larger than all examples\")\n",
        "        batch_data = self._data[self._indicator: end_indicator]\n",
        "        batch_labels = self._labels[self._indicator: end_indicator]\n",
        "        self._indicator = end_indicator\n",
        "        return batch_data, batch_labels\n",
        "\n",
        "train_data = CifarData(x_img_train, y_label_train, True)\n",
        "test_data = CifarData(x_img_test, y_label_test, False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 3072)\n",
            "(50000,)\n",
            "(10000, 3072)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oD7xDXCUYrp",
        "colab_type": "code",
        "outputId": "c3894855-a22f-420f-ead0-1837b28287d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(set([item[0] for item in y_label_train]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU1WejbrVnjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 3072])\n",
        "y = tf.placeholder(tf.int64, [None])\n",
        "\n",
        "#w = tf.get_variable('w', [x.get_shape()[-1], 1], initializer=tf.random_normal_initializer(0, 1))\n",
        "#b = tf.get_variable('b', [1], initializer=tf.constant_initializer(0))\n",
        "w = tf.get_variable('w', [x.get_shape()[-1], 10], initializer=tf.random_normal_initializer(0, 1))\n",
        "b = tf.get_variable('b', [10], initializer=tf.constant_initializer(0))\n",
        "\n",
        "y_ = tf.matmul(x, w) + b\n",
        "\n",
        "# p_y_1 = tf.nn.sigmoid(y_)\n",
        "# y_reshaped = tf.reshape(y, (-1, 1))\n",
        "p_y = tf.nn.softmax(y_)\n",
        "y_one_hot = tf.one_hot(y, 10, dtype=tf.float32)\n",
        "\n",
        "loss = tf.reduce_mean(tf.square(y_one_hot - p_y))\n",
        "\n",
        "loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
        "\n",
        "# indices\n",
        "predict = tf.argmax(y_, 1)\n",
        "correct_prediction = tf.equal(predict, y)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
        "\n",
        "with tf.name_scope(\"train_op\"):\n",
        "    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctfrsws9byS5",
        "colab_type": "code",
        "outputId": "9297431c-5a45-4bde-a7b9-c14f5a670471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "batch_size = 20\n",
        "train_steps = 100000\n",
        "test_steps = 100\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(train_steps):\n",
        "        batch_data, batch_labels = train_data.next_batch(batch_size)\n",
        "        loss_val, acc_val, _ = sess.run(\n",
        "            [loss, accuracy, train_op],\n",
        "            feed_dict={x: batch_data, y: batch_labels})\n",
        "        if (i+1) % 500 == 0:\n",
        "            print('[Train] Step: %d, loss: %4.5f, acc: %4.5f' \\\n",
        "                % (i+1, loss_val, acc_val))\n",
        "        if (i+1) % 5000 == 0:\n",
        "            test_data = CifarData(x_img_test, y_label_test, False)\n",
        "            all_test_acc_val = []\n",
        "            for j in range(test_steps):\n",
        "                test_batch_data, test_batch_labels \\\n",
        "                    = test_data.next_batch(batch_size)\n",
        "                test_acc_val = sess.run(\n",
        "                    [accuracy],\n",
        "                    feed_dict = {\n",
        "                        x: test_batch_data, \n",
        "                        y: test_batch_labels\n",
        "                    })\n",
        "                all_test_acc_val.append(test_acc_val)\n",
        "            test_acc = np.mean(all_test_acc_val)\n",
        "            print('[Test ] Step: %d, acc: %4.5f' % (i+1, test_acc))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Train] Step: 500, loss: 12.32553, acc: 0.25000\n",
            "[Train] Step: 1000, loss: 11.45547, acc: 0.20000\n",
            "[Train] Step: 1500, loss: 9.28195, acc: 0.20000\n",
            "[Train] Step: 2000, loss: 16.18590, acc: 0.10000\n",
            "[Train] Step: 2500, loss: 10.96650, acc: 0.35000\n",
            "[Train] Step: 3000, loss: 8.29427, acc: 0.40000\n",
            "[Train] Step: 3500, loss: 10.29505, acc: 0.15000\n",
            "[Train] Step: 4000, loss: 10.03922, acc: 0.15000\n",
            "[Train] Step: 4500, loss: 10.27045, acc: 0.15000\n",
            "[Train] Step: 5000, loss: 9.97001, acc: 0.20000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 5000, acc: 0.28000\n",
            "[Train] Step: 5500, loss: 4.53131, acc: 0.40000\n",
            "[Train] Step: 6000, loss: 7.77492, acc: 0.35000\n",
            "[Train] Step: 6500, loss: 8.55934, acc: 0.25000\n",
            "[Train] Step: 7000, loss: 7.36624, acc: 0.25000\n",
            "[Train] Step: 7500, loss: 6.63871, acc: 0.25000\n",
            "[Train] Step: 8000, loss: 6.45370, acc: 0.25000\n",
            "[Train] Step: 8500, loss: 5.94166, acc: 0.25000\n",
            "[Train] Step: 9000, loss: 4.21311, acc: 0.35000\n",
            "[Train] Step: 9500, loss: 5.87860, acc: 0.35000\n",
            "[Train] Step: 10000, loss: 7.26554, acc: 0.25000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 10000, acc: 0.28650\n",
            "[Train] Step: 10500, loss: 6.51290, acc: 0.10000\n",
            "[Train] Step: 11000, loss: 3.80819, acc: 0.50000\n",
            "[Train] Step: 11500, loss: 2.59111, acc: 0.35000\n",
            "[Train] Step: 12000, loss: 7.91277, acc: 0.15000\n",
            "[Train] Step: 12500, loss: 5.48494, acc: 0.25000\n",
            "[Train] Step: 13000, loss: 4.06838, acc: 0.50000\n",
            "[Train] Step: 13500, loss: 4.64935, acc: 0.45000\n",
            "[Train] Step: 14000, loss: 3.73559, acc: 0.40000\n",
            "[Train] Step: 14500, loss: 4.50306, acc: 0.25000\n",
            "[Train] Step: 15000, loss: 4.13429, acc: 0.20000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 15000, acc: 0.28250\n",
            "[Train] Step: 15500, loss: 7.64272, acc: 0.05000\n",
            "[Train] Step: 16000, loss: 4.42412, acc: 0.35000\n",
            "[Train] Step: 16500, loss: 3.67878, acc: 0.25000\n",
            "[Train] Step: 17000, loss: 7.14729, acc: 0.15000\n",
            "[Train] Step: 17500, loss: 5.53023, acc: 0.25000\n",
            "[Train] Step: 18000, loss: 3.98567, acc: 0.35000\n",
            "[Train] Step: 18500, loss: 6.37391, acc: 0.25000\n",
            "[Train] Step: 19000, loss: 3.13355, acc: 0.25000\n",
            "[Train] Step: 19500, loss: 3.52245, acc: 0.25000\n",
            "[Train] Step: 20000, loss: 4.05151, acc: 0.30000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 20000, acc: 0.28250\n",
            "[Train] Step: 20500, loss: 4.86700, acc: 0.15000\n",
            "[Train] Step: 21000, loss: 5.39645, acc: 0.15000\n",
            "[Train] Step: 21500, loss: 2.54171, acc: 0.30000\n",
            "[Train] Step: 22000, loss: 5.31503, acc: 0.40000\n",
            "[Train] Step: 22500, loss: 4.47609, acc: 0.25000\n",
            "[Train] Step: 23000, loss: 4.94249, acc: 0.20000\n",
            "[Train] Step: 23500, loss: 3.90620, acc: 0.30000\n",
            "[Train] Step: 24000, loss: 4.15874, acc: 0.35000\n",
            "[Train] Step: 24500, loss: 4.28086, acc: 0.25000\n",
            "[Train] Step: 25000, loss: 3.54058, acc: 0.35000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 25000, acc: 0.29600\n",
            "[Train] Step: 25500, loss: 2.30237, acc: 0.45000\n",
            "[Train] Step: 26000, loss: 3.92250, acc: 0.35000\n",
            "[Train] Step: 26500, loss: 3.94813, acc: 0.40000\n",
            "[Train] Step: 27000, loss: 4.22003, acc: 0.35000\n",
            "[Train] Step: 27500, loss: 2.14130, acc: 0.35000\n",
            "[Train] Step: 28000, loss: 2.94989, acc: 0.20000\n",
            "[Train] Step: 28500, loss: 3.34820, acc: 0.20000\n",
            "[Train] Step: 29000, loss: 3.28519, acc: 0.30000\n",
            "[Train] Step: 29500, loss: 3.68839, acc: 0.35000\n",
            "[Train] Step: 30000, loss: 3.49184, acc: 0.20000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 30000, acc: 0.28800\n",
            "[Train] Step: 30500, loss: 3.43432, acc: 0.25000\n",
            "[Train] Step: 31000, loss: 3.58239, acc: 0.30000\n",
            "[Train] Step: 31500, loss: 3.47494, acc: 0.35000\n",
            "[Train] Step: 32000, loss: 2.62247, acc: 0.30000\n",
            "[Train] Step: 32500, loss: 3.29913, acc: 0.25000\n",
            "[Train] Step: 33000, loss: 3.01226, acc: 0.25000\n",
            "[Train] Step: 33500, loss: 3.44188, acc: 0.30000\n",
            "[Train] Step: 34000, loss: 2.79737, acc: 0.50000\n",
            "[Train] Step: 34500, loss: 3.33519, acc: 0.30000\n",
            "[Train] Step: 35000, loss: 2.41100, acc: 0.45000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 35000, acc: 0.29400\n",
            "[Train] Step: 35500, loss: 3.30362, acc: 0.35000\n",
            "[Train] Step: 36000, loss: 2.03120, acc: 0.50000\n",
            "[Train] Step: 36500, loss: 3.35272, acc: 0.40000\n",
            "[Train] Step: 37000, loss: 2.31542, acc: 0.50000\n",
            "[Train] Step: 37500, loss: 3.30611, acc: 0.15000\n",
            "[Train] Step: 38000, loss: 3.16984, acc: 0.25000\n",
            "[Train] Step: 38500, loss: 3.77617, acc: 0.30000\n",
            "[Train] Step: 39000, loss: 1.97774, acc: 0.60000\n",
            "[Train] Step: 39500, loss: 3.21930, acc: 0.30000\n",
            "[Train] Step: 40000, loss: 3.84828, acc: 0.20000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 40000, acc: 0.29650\n",
            "[Train] Step: 40500, loss: 3.49282, acc: 0.25000\n",
            "[Train] Step: 41000, loss: 2.66795, acc: 0.40000\n",
            "[Train] Step: 41500, loss: 3.15482, acc: 0.20000\n",
            "[Train] Step: 42000, loss: 2.29321, acc: 0.35000\n",
            "[Train] Step: 42500, loss: 2.11886, acc: 0.40000\n",
            "[Train] Step: 43000, loss: 2.79329, acc: 0.30000\n",
            "[Train] Step: 43500, loss: 1.80607, acc: 0.35000\n",
            "[Train] Step: 44000, loss: 3.45655, acc: 0.25000\n",
            "[Train] Step: 44500, loss: 2.61965, acc: 0.25000\n",
            "[Train] Step: 45000, loss: 2.63610, acc: 0.35000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 45000, acc: 0.29250\n",
            "[Train] Step: 45500, loss: 3.45370, acc: 0.45000\n",
            "[Train] Step: 46000, loss: 2.61946, acc: 0.40000\n",
            "[Train] Step: 46500, loss: 2.70537, acc: 0.25000\n",
            "[Train] Step: 47000, loss: 3.23710, acc: 0.25000\n",
            "[Train] Step: 47500, loss: 2.30824, acc: 0.40000\n",
            "[Train] Step: 48000, loss: 2.21640, acc: 0.50000\n",
            "[Train] Step: 48500, loss: 2.22094, acc: 0.40000\n",
            "[Train] Step: 49000, loss: 2.76273, acc: 0.40000\n",
            "[Train] Step: 49500, loss: 2.21976, acc: 0.25000\n",
            "[Train] Step: 50000, loss: 2.62239, acc: 0.35000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 50000, acc: 0.29050\n",
            "[Train] Step: 50500, loss: 3.03653, acc: 0.35000\n",
            "[Train] Step: 51000, loss: 2.79974, acc: 0.30000\n",
            "[Train] Step: 51500, loss: 3.43137, acc: 0.35000\n",
            "[Train] Step: 52000, loss: 1.46740, acc: 0.55000\n",
            "[Train] Step: 52500, loss: 4.04875, acc: 0.25000\n",
            "[Train] Step: 53000, loss: 2.33946, acc: 0.25000\n",
            "[Train] Step: 53500, loss: 1.79433, acc: 0.40000\n",
            "[Train] Step: 54000, loss: 2.08041, acc: 0.50000\n",
            "[Train] Step: 54500, loss: 3.47115, acc: 0.25000\n",
            "[Train] Step: 55000, loss: 2.69123, acc: 0.30000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 55000, acc: 0.30700\n",
            "[Train] Step: 55500, loss: 3.70285, acc: 0.30000\n",
            "[Train] Step: 56000, loss: 1.68745, acc: 0.40000\n",
            "[Train] Step: 56500, loss: 2.72024, acc: 0.25000\n",
            "[Train] Step: 57000, loss: 2.49027, acc: 0.35000\n",
            "[Train] Step: 57500, loss: 4.58586, acc: 0.10000\n",
            "[Train] Step: 58000, loss: 1.86332, acc: 0.45000\n",
            "[Train] Step: 58500, loss: 2.95899, acc: 0.20000\n",
            "[Train] Step: 59000, loss: 3.28305, acc: 0.10000\n",
            "[Train] Step: 59500, loss: 3.53646, acc: 0.25000\n",
            "[Train] Step: 60000, loss: 2.88809, acc: 0.45000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 60000, acc: 0.29800\n",
            "[Train] Step: 60500, loss: 2.30425, acc: 0.35000\n",
            "[Train] Step: 61000, loss: 3.38456, acc: 0.30000\n",
            "[Train] Step: 61500, loss: 2.51366, acc: 0.55000\n",
            "[Train] Step: 62000, loss: 3.57337, acc: 0.15000\n",
            "[Train] Step: 62500, loss: 2.70231, acc: 0.30000\n",
            "[Train] Step: 63000, loss: 2.97416, acc: 0.25000\n",
            "[Train] Step: 63500, loss: 3.15861, acc: 0.45000\n",
            "[Train] Step: 64000, loss: 2.67876, acc: 0.25000\n",
            "[Train] Step: 64500, loss: 3.77130, acc: 0.25000\n",
            "[Train] Step: 65000, loss: 3.38902, acc: 0.25000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 65000, acc: 0.31350\n",
            "[Train] Step: 65500, loss: 2.75692, acc: 0.40000\n",
            "[Train] Step: 66000, loss: 2.72500, acc: 0.25000\n",
            "[Train] Step: 66500, loss: 4.33733, acc: 0.20000\n",
            "[Train] Step: 67000, loss: 2.79250, acc: 0.25000\n",
            "[Train] Step: 67500, loss: 2.78859, acc: 0.25000\n",
            "[Train] Step: 68000, loss: 3.10293, acc: 0.25000\n",
            "[Train] Step: 68500, loss: 2.01650, acc: 0.50000\n",
            "[Train] Step: 69000, loss: 2.01431, acc: 0.35000\n",
            "[Train] Step: 69500, loss: 2.69764, acc: 0.20000\n",
            "[Train] Step: 70000, loss: 2.25616, acc: 0.45000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 70000, acc: 0.31200\n",
            "[Train] Step: 70500, loss: 2.66071, acc: 0.30000\n",
            "[Train] Step: 71000, loss: 2.60882, acc: 0.30000\n",
            "[Train] Step: 71500, loss: 2.32406, acc: 0.25000\n",
            "[Train] Step: 72000, loss: 2.65920, acc: 0.30000\n",
            "[Train] Step: 72500, loss: 2.30603, acc: 0.40000\n",
            "[Train] Step: 73000, loss: 2.12647, acc: 0.40000\n",
            "[Train] Step: 73500, loss: 3.00189, acc: 0.35000\n",
            "[Train] Step: 74000, loss: 1.83162, acc: 0.35000\n",
            "[Train] Step: 74500, loss: 2.53747, acc: 0.35000\n",
            "[Train] Step: 75000, loss: 2.76004, acc: 0.25000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 75000, acc: 0.30750\n",
            "[Train] Step: 75500, loss: 2.25446, acc: 0.35000\n",
            "[Train] Step: 76000, loss: 1.57757, acc: 0.55000\n",
            "[Train] Step: 76500, loss: 2.99456, acc: 0.20000\n",
            "[Train] Step: 77000, loss: 2.66016, acc: 0.35000\n",
            "[Train] Step: 77500, loss: 2.62040, acc: 0.35000\n",
            "[Train] Step: 78000, loss: 2.42707, acc: 0.25000\n",
            "[Train] Step: 78500, loss: 3.34837, acc: 0.15000\n",
            "[Train] Step: 79000, loss: 2.56072, acc: 0.30000\n",
            "[Train] Step: 79500, loss: 2.27062, acc: 0.40000\n",
            "[Train] Step: 80000, loss: 2.41723, acc: 0.25000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 80000, acc: 0.31500\n",
            "[Train] Step: 80500, loss: 1.79020, acc: 0.50000\n",
            "[Train] Step: 81000, loss: 1.78156, acc: 0.40000\n",
            "[Train] Step: 81500, loss: 2.27252, acc: 0.50000\n",
            "[Train] Step: 82000, loss: 2.20535, acc: 0.35000\n",
            "[Train] Step: 82500, loss: 2.49059, acc: 0.45000\n",
            "[Train] Step: 83000, loss: 1.62526, acc: 0.50000\n",
            "[Train] Step: 83500, loss: 2.70155, acc: 0.30000\n",
            "[Train] Step: 84000, loss: 2.60700, acc: 0.20000\n",
            "[Train] Step: 84500, loss: 2.13735, acc: 0.40000\n",
            "[Train] Step: 85000, loss: 1.54106, acc: 0.45000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 85000, acc: 0.30650\n",
            "[Train] Step: 85500, loss: 1.95456, acc: 0.40000\n",
            "[Train] Step: 86000, loss: 2.07316, acc: 0.45000\n",
            "[Train] Step: 86500, loss: 2.33458, acc: 0.35000\n",
            "[Train] Step: 87000, loss: 2.54815, acc: 0.25000\n",
            "[Train] Step: 87500, loss: 2.29823, acc: 0.30000\n",
            "[Train] Step: 88000, loss: 2.44105, acc: 0.50000\n",
            "[Train] Step: 88500, loss: 2.21637, acc: 0.40000\n",
            "[Train] Step: 89000, loss: 1.75771, acc: 0.45000\n",
            "[Train] Step: 89500, loss: 1.44690, acc: 0.45000\n",
            "[Train] Step: 90000, loss: 1.09839, acc: 0.65000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 90000, acc: 0.30900\n",
            "[Train] Step: 90500, loss: 2.56937, acc: 0.35000\n",
            "[Train] Step: 91000, loss: 2.39041, acc: 0.45000\n",
            "[Train] Step: 91500, loss: 2.14407, acc: 0.40000\n",
            "[Train] Step: 92000, loss: 3.33552, acc: 0.30000\n",
            "[Train] Step: 92500, loss: 2.28131, acc: 0.25000\n",
            "[Train] Step: 93000, loss: 2.52374, acc: 0.25000\n",
            "[Train] Step: 93500, loss: 2.09234, acc: 0.35000\n",
            "[Train] Step: 94000, loss: 2.40224, acc: 0.40000\n",
            "[Train] Step: 94500, loss: 2.27371, acc: 0.40000\n",
            "[Train] Step: 95000, loss: 1.46082, acc: 0.65000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 95000, acc: 0.32300\n",
            "[Train] Step: 95500, loss: 1.34979, acc: 0.50000\n",
            "[Train] Step: 96000, loss: 2.47026, acc: 0.20000\n",
            "[Train] Step: 96500, loss: 2.83082, acc: 0.35000\n",
            "[Train] Step: 97000, loss: 2.48590, acc: 0.25000\n",
            "[Train] Step: 97500, loss: 3.40830, acc: 0.20000\n",
            "[Train] Step: 98000, loss: 2.78247, acc: 0.40000\n",
            "[Train] Step: 98500, loss: 2.68695, acc: 0.35000\n",
            "[Train] Step: 99000, loss: 2.54549, acc: 0.35000\n",
            "[Train] Step: 99500, loss: 1.63570, acc: 0.35000\n",
            "[Train] Step: 100000, loss: 2.78566, acc: 0.40000\n",
            "(10000, 3072)\n",
            "(10000,)\n",
            "[Test ] Step: 100000, acc: 0.31600\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}